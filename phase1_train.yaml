name: phase1_train
description: Train the Phase 1 ResNet50 classifier, output best model and logs.
inputs:
  - {name: train_data, type: Dataset, description: "Training dataset"}
  - {name: val_data, type: Dataset, description: "Validation dataset"}
  - {name: test_data, type: Dataset, description: "Test dataset"}
  - {name: phase1_model_init, type: Model, description: "Model initialization weights (phase1_model_init.pt)"}
  - {name: phase1_model_meta, type: String, description: "Model metadata (phase1_model_meta.json)"}

outputs:
  - {name: phase1_resnet50_best, type: Model, description: "Best model checkpoint (phase1_resnet50_best.pt)"}
  - {name: phase1_label_maps, type: Dataset, description: "Category to index and index to category mapping (phase1_label_maps.json)"}
  - {name: phase1_train_log, type: Dataset, description: "Training log with best validation accuracy (phase1_train_log.json)"}

implementation:
  container:
    image: python:3.9
    command:
      - bash
      - -ec
      - |
        set -euo pipefail

        # ---- System & Python deps ----
        apt-get update -y && apt-get install -y python3-pip
        python -m pip install --no-cache-dir torch torchvision pillow

        # ---- Set environment variables for the script ----
        export TRAIN_DATA_PATH="$1"
        export VAL_DATA_PATH="$2"
        export TEST_DATA_PATH="$3"
        export MODEL_INIT_PATH="$4"
        export MODEL_META_PATH="$5"
        export OUTPUT_DIR="$6"

        # ---- Python script for training ----
        cat > /tmp/phase1_train.py <<'PY'
        import argparse, json, time, random, torch, torch.nn as nn
        from pathlib import Path
        from torch.utils.data import Dataset, DataLoader
        from torchvision import transforms
        from PIL import Image

        # Constants
        IMG_EXTS = {".jpg", ".jpeg", ".png", ".webp"}

        def set_seed(seed=42):
            random.seed(seed)
            torch.manual_seed(seed)
            torch.cuda.manual_seed_all(seed)

        def list_images_under_category(category_dir: Path):
            files = []
            for comp_dir in category_dir.iterdir():
                if comp_dir.is_dir():
                    for f in comp_dir.iterdir():
                        if f.is_file() and f.suffix.lower() in IMG_EXTS:
                            files.append(f)
            return files

        class UICategoryDataset(Dataset):
            def __init__(self, split_root: Path, category_to_idx: dict, transform=None):
                self.transform = transform
                self.samples = []
                self.category_to_idx = category_to_idx
                for cat in sorted(category_to_idx.keys()):
                    cat_dir = split_root / cat
                    if not cat_dir.exists(): 
                        continue
                    for img_path in list_images_under_category(cat_dir):
                        self.samples.append((img_path, category_to_idx[cat]))
                if len(self.samples) == 0:
                    raise RuntimeError(f"No images found under {split_root}.")

            def __len__(self): return len(self.samples)

            def __getitem__(self, idx):
                path, y = self.samples[idx]
                img = Image.open(path).convert("RGB")
                if self.transform: img = self.transform(img)
                return img, y

        def accuracy(outputs, targets):
            preds = outputs.argmax(dim=1)
            return (preds == targets).float().mean().item()

        def evaluate(model, loader, device, criterion):
            model.eval()
            running_loss, running_acc, n = 0.0, 0.0, 0
            with torch.no_grad():
                for x, y in loader:
                    x, y = x.to(device), y.to(device)
                    with torch.cuda.amp.autocast():
                        logits = model(x)
                        loss = criterion(logits, y)
                    bs = y.size(0)
                    running_loss += loss.item() * bs
                    running_acc  += accuracy(logits, y) * bs
                    n += bs
            return running_loss / n, running_acc / n

        def main():
            ap = argparse.ArgumentParser()
            ap.add_argument("--dataset_root", type=Path, required=True, help="Root for train, val, test datasets")
            ap.add_argument("--model_init", type=Path, required=True, help="Path to model initialization weights")
            ap.add_argument("--model_meta", type=Path, required=True, help="Path to model metadata")
            ap.add_argument("--out_dir", type=Path, required=True, help="Output directory for model and logs")
            ap.add_argument("--epochs", type=int, default=10)
            ap.add_argument("--batch_size", type=int, default=32)
            ap.add_argument("--lr", type=float, default=3e-4)
            ap.add_argument("--weight_decay", type=float, default=1e-4)
            ap.add_argument("--num_workers", type=int, default=2)
            ap.add_argument("--seed", type=int, default=42)
            args = ap.parse_args()

            set_seed(args.seed)
            args.out_dir.mkdir(parents=True, exist_ok=True)

            meta = json.loads(Path(args.model_meta).read_text())
            categories = meta["categories"]
            category_to_idx = {c:i for i,c in enumerate(categories)}
            idx_to_category = {i:c for c,i in category_to_idx.items()}

            # Transformations
            image_size = meta["image_size"]
            train_tfms = transforms.Compose([
                transforms.Resize((image_size, image_size)),
                transforms.RandomHorizontalFlip(),
                transforms.RandomResizedCrop(image_size),
                transforms.ToTensor(),
                transforms.Normalize(mean=meta["mean"], std=meta["std"]),
            ])
            eval_tfms = transforms.Compose([
                transforms.Resize((image_size, image_size)),
                transforms.ToTensor(),
                transforms.Normalize(mean=meta["mean"], std=meta["std"]),
            ])

            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

            # Load datasets and dataloaders
            train_ds = UICategoryDataset(args.dataset_root / "train", category_to_idx, transform=train_tfms)
            val_ds   = UICategoryDataset(args.dataset_root / "val", category_to_idx, transform=eval_tfms)
            train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True)
            val_loader   = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False)

            # Load model
            state = torch.load(args.model_init, map_location=device)
            from torchvision.models import resnet50
            model = resnet50(pretrained=False)
            model.fc = nn.Sequential(nn.Dropout(p=0.2), nn.Linear(model.fc.in_features, len(categories)))
            model.load_state_dict(state, strict=True)
            model.to(device)

            # Loss, optimizer, and scheduler
            criterion = nn.CrossEntropyLoss(label_smoothing=0.05)
            optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)

            best_val_acc = 0.0
            for epoch in range(1, args.epochs + 1):
                model.train()
                epoch_loss = 0.0
                epoch_acc = 0.0
                seen = 0
                for x, y in train_loader:
                    x, y = x.to(device), y.to(device)
                    optimizer.zero_grad()
                    with torch.cuda.amp.autocast():
                        logits = model(x)
                        loss = criterion(logits, y)
                    loss.backward()
                    optimizer.step()
                    epoch_loss += loss.item() * y.size(0)
                    epoch_acc += accuracy(logits, y) * y.size(0)
                    seen += y.size(0)

                train_loss = epoch_loss / seen
                train_acc = epoch_acc / seen
                val_loss, val_acc = evaluate(model, val_loader, device, criterion)

                if val_acc > best_val_acc:
                    best_val_acc = val_acc
                    torch.save({
                        "model_state": model.state_dict(),
                        "category_to_idx": category_to_idx,
                        "idx_to_category": idx_to_category,
                        "image_size": image_size,
                    }, args.out_dir / "phase1_resnet50_best.pt")

            # Save outputs
            (args.out_dir / "phase1_label_maps.json").write_text(json.dumps({
                "category_to_idx": category_to_idx,
                "idx_to_category": idx_to_category
            }, indent=2))
            (args.out_dir / "phase1_train_log.json").write_text(json.dumps({
                "best_val_acc": best_val_acc
            }, indent=2))

        if __name__ == "__main__":
            main()
        PY

        python /tmp/phase1_train.py
    args:
      - {inputPath: train_data}
      - {inputPath: val_data}
      - {inputPath: test_data}
      - {inputPath: phase1_model_init}
      - {inputPath: phase1_model_meta}
      - {outputPath: phase1_resnet50_best}
      - {outputPath: phase1_label_maps}
      - {outputPath: phase1_train_log}
