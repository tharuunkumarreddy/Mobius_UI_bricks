name: Phase1 Train ResNet50 Model
description: Train the Phase 1 ResNet50 classifier for UI category classification
inputs:
  - {name: train_dataset, type: Dataset}       # Training dataset directory
  - {name: val_dataset, type: Dataset}         # Validation dataset directory
  - {name: test_dataset, type: Dataset}        # Test dataset directory
  - {name: model_init, type: Model}            # phase1_model_init.pt file
  - {name: model_meta, type: String}           # phase1_model_meta.json content
outputs:
  - {name: trained_model, type: Model}         # phase1_resnet50_best.pt
  - {name: label_maps, type: String}           # phase1_label_maps.json
  - {name: train_log, type: String}            # phase1_train_log.json
implementation:
  container:
    image: pytorch/pytorch:2.0.1-cuda11.7-cudnn8-devel
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse, json, math, random, time
        from pathlib import Path
        import numpy as np
        import torch, torch.nn as nn, torch.backends.cudnn as cudnn
        from torch.utils.data import Dataset, DataLoader
        from torchvision import transforms
        from PIL import Image
        import os
        
        # Install required packages
        import subprocess
        import sys
        
        def install_package(package):
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])
        
        try:
            import torchvision
        except ImportError:
            install_package("torchvision")
            import torchvision
        
        try:
            from PIL import Image
        except ImportError:
            install_package("Pillow")
            from PIL import Image
        
        IMG_EXTS = {".jpg", ".jpeg", ".png", ".webp"}

        def set_seed(seed=42):
            random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)
            torch.cuda.manual_seed_all(seed); cudnn.deterministic = False; cudnn.benchmark = True

        def list_images_under_category(category_dir: Path):
            files = []
            for comp_dir in category_dir.iterdir():
                if comp_dir.is_dir():
                    for f in comp_dir.iterdir():
                        if f.is_file() and f.suffix.lower() in IMG_EXTS:
                            files.append(f)
            return files

        class UICategoryDataset(Dataset):
            def __init__(self, split_root: Path, category_to_idx: dict, transform=None):
                self.transform = transform
                self.samples = []
                self.category_to_idx = category_to_idx
                for cat in sorted(category_to_idx.keys()):
                    cat_dir = split_root / cat
                    if not cat_dir.exists(): 
                        continue
                    for img_path in list_images_under_category(cat_dir):
                        self.samples.append((img_path, category_to_idx[cat]))
                if len(self.samples) == 0:
                    raise RuntimeError(f"No images found under {split_root}.")

            def __len__(self): return len(self.samples)

            def __getitem__(self, idx):
                path, y = self.samples[idx]
                img = Image.open(path).convert("RGB")
                if self.transform: img = self.transform(img)
                return img, y

        def accuracy(outputs, targets):
            preds = outputs.argmax(dim=1)
            return (preds == targets).float().mean().item()

        def evaluate(model, loader, device, criterion):
            model.eval()
            running_loss, running_acc, n = 0.0, 0.0, 0
            with torch.no_grad():
                for x, y in loader:
                    x, y = x.to(device), y.to(device)
                    with torch.cuda.amp.autocast():
                        logits = model(x)
                        loss = criterion(logits, y)
                    bs = y.size(0)
                    running_loss += loss.item() * bs
                    running_acc  += accuracy(logits, y) * bs
                    n += bs
            return running_loss / n, running_acc / n

        # Parse arguments
        parser = argparse.ArgumentParser()
        parser.add_argument('--train_dataset', type=str, required=True)
        parser.add_argument('--val_dataset', type=str, required=True)
        parser.add_argument('--test_dataset', type=str, required=True)
        parser.add_argument('--model_init', type=str, required=True)
        parser.add_argument('--model_meta', type=str, required=True)
        parser.add_argument('--trained_model', type=str, required=True)
        parser.add_argument('--label_maps', type=str, required=True)
        parser.add_argument('--train_log', type=str, required=True)
        parser.add_argument('--epochs', type=int, default=10)
        parser.add_argument('--batch_size', type=int, default=32)
        parser.add_argument('--lr', type=float, default=3e-4)
        parser.add_argument('--weight_decay', type=float, default=1e-4)
        parser.add_argument('--num_workers', type=int, default=2)
        parser.add_argument('--seed', type=int, default=42)
        args = parser.parse_args()

        print(f"Train dataset: {args.train_dataset}")
        print(f"Val dataset: {args.val_dataset}")
        print(f"Test dataset: {args.test_dataset}")
        print(f"Model init: {args.model_init}")
        print(f"Model meta: {args.model_meta}")
        print(f"Trained model output: {args.trained_model}")
        print(f"Label maps output: {args.label_maps}")
        print(f"Train log output: {args.train_log}")

        set_seed(args.seed)

        # Create output directories
        for output_path in [args.trained_model, args.label_maps, args.train_log]:
            output_dir = os.path.dirname(output_path)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir, exist_ok=True)

        # Load metadata
        try:
            # model_meta is passed as inputValue (JSON string content)
            meta = json.loads(args.model_meta)
            print("Loaded metadata from JSON string")
        except Exception as e:
            print(f"Error loading model metadata: {e}")
            exit(1)
            
        image_size = meta["image_size"]
        mean, std = meta["mean"], meta["std"]
        categories = meta["categories"]
        category_to_idx = {c:i for i,c in enumerate(categories)}
        idx_to_category = {i:c for c,i in category_to_idx.items()}

        train_tfms = transforms.Compose([
            transforms.Resize((image_size, image_size)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.15, hue=0.02),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std),
        ])
        eval_tfms = transforms.Compose([
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std),
        ])

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Using device: {device}")

        # Build datasets/loaders
        train_ds = UICategoryDataset(Path(args.train_dataset), category_to_idx, transform=train_tfms)
        val_ds   = UICategoryDataset(Path(args.val_dataset), category_to_idx, transform=eval_tfms)
        train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True,
                                  num_workers=args.num_workers, pin_memory=True)
        val_loader   = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False,
                                  num_workers=args.num_workers, pin_memory=True)

        # Load model
        try:
            state = torch.load(args.model_init, map_location="cpu")
            from torchvision.models import resnet50, ResNet50_Weights
            m = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)
            m.fc = nn.Sequential(nn.Dropout(p=0.2), nn.Linear(m.fc.in_features, len(categories)))
            m.load_state_dict(state, strict=True)
            m.to(device)
            print("Model loaded successfully")
        except Exception as e:
            print(f"Error loading model: {e}")
            exit(1)

        # Loss/optim/sched
        criterion = nn.CrossEntropyLoss(label_smoothing=0.05)
        optimizer = torch.optim.AdamW(m.parameters(), lr=args.lr, weight_decay=args.weight_decay)

        total_steps = args.epochs * (len(train_loader) if len(train_loader) > 0 else 1)
        warmup_steps = max(100, int(0.05 * total_steps))
        def lr_lambda(step):
            if step < warmup_steps:
                return float(step) / float(max(1, warmup_steps))
            progress = (step - warmup_steps) / float(max(1, total_steps - warmup_steps))
            return 0.5 * (1.0 + math.cos(math.pi * progress))
        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)
        scaler = torch.cuda.amp.GradScaler()

        # Train
        print("Starting training...")
        best_val_acc = 0.0
        for epoch in range(1, args.epochs + 1):
            m.train(); epoch_loss = 0.0; epoch_acc = 0.0; seen = 0
            t0 = time.time()
            for x, y in train_loader:
                x, y = x.to(device), y.to(device)
                optimizer.zero_grad(set_to_none=True)
                with torch.cuda.amp.autocast():
                    logits = m(x)
                    loss = criterion(logits, y)
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
                scheduler.step()
                bs = y.size(0)
                epoch_loss += loss.item() * bs
                epoch_acc  += ((logits.argmax(1) == y).float().mean().item()) * bs
                seen += bs
            train_loss = epoch_loss / max(1, seen)
            train_acc  = epoch_acc  / max(1, seen)
            val_loss, val_acc = evaluate(m, val_loader, device, criterion)
            dt = time.time() - t0
            print(f"Epoch {epoch:02d}/{args.epochs} | {dt:.1f}s | train loss {train_loss:.4f} acc {train_acc:.3f} | val loss {val_loss:.4f} acc {val_acc:.3f}")

            if val_acc > best_val_acc:
                best_val_acc = val_acc
                torch.save({
                    "model_state": m.state_dict(),
                    "category_to_idx": category_to_idx,
                    "idx_to_category": idx_to_category,
                    "image_size": image_size,
                }, args.trained_model)
                print(f"✓ Saved new best to {args.trained_model} (val_acc={val_acc:.3f})")

        # Save sidecar outputs
        try:
            label_maps_data = {
                "category_to_idx": category_to_idx, 
                "idx_to_category": idx_to_category
            }
            with open(args.label_maps, 'w') as f:
                json.dump(label_maps_data, f, indent=2)
            
            train_log_data = {
                "best_val_acc": best_val_acc
            }
            with open(args.train_log, 'w') as f:
                json.dump(train_log_data, f, indent=2)
            
            print(f"Saved label maps to {args.label_maps}")
            print(f"Saved training log to {args.train_log}")
            print(f"Best validation accuracy: {best_val_acc:.3f}")
        except Exception as e:
            print(f"Error saving outputs: {e}")
            exit(1)
    args:
      - --train_dataset
      - {inputPath: train_dataset}
      - --val_dataset
      - {inputPath: val_dataset}
      - --test_dataset
      - {inputPath: test_dataset}
      - --model_init
      - {inputPath: model_init}
      - --model_meta
      - {inputValue: model_meta}
      - --trained_model
      - {outputPath: trained_model}
      - --label_maps
      - {outputPath: label_maps}
      - --train_log
      - {outputPath: train_log}
