name: Phase1 Train ResNet50 Model
description: Train the Phase 1 ResNet50 classifier for UI category classification
inputs:
  - {name: train_dataset, type: Dataset}       # Training dataset directory
  - {name: val_dataset, type: Dataset}         # Validation dataset directory
  - {name: test_dataset, type: Dataset}        # Test dataset directory
  - {name: model_init, type: Model}            # phase1_model_init.pt file
  - {name: model_meta, type: String}           # phase1_model_meta.json content
outputs:
  - {name: trained_model, type: Model}         # phase1_resnet50_best.pt
  - {name: label_maps, type: String}           # phase1_label_maps.json
  - {name: train_log, type: String}            # phase1_train_log.json
implementation:
  container:
    image: pytorch/pytorch:2.0.1-cuda11.7-cudnn8-devel
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse, json, math, random, time
        from pathlib import Path
        import numpy as np
        import torch, torch.nn as nn, torch.backends.cudnn as cudnn
        from torch.utils.data import Dataset, DataLoader
        from torchvision import transforms
        from PIL import Image
        import os
        
        # Install required packages
        import subprocess
        import sys
        
        def install_package(package):
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])
        
        try:
            import torchvision
        except ImportError:
            install_package("torchvision")
            import torchvision
        
        try:
            from PIL import Image
        except ImportError:
            install_package("Pillow")
            from PIL import Image
        
        # Also ensure we can handle compressed files
        import zipfile
        import tarfile
        import shutil
        
        IMG_EXTS = {".jpg", ".jpeg", ".png", ".webp"}

        def extract_if_compressed(file_path, extract_to):
            """Extract compressed file if needed and return the directory path"""
            file_path = Path(file_path)
            extract_to = Path(extract_to)
            
            if not file_path.is_file():
                return file_path  # Return as-is if it's not a file
                
            print(f"Attempting to extract {file_path} to {extract_to}")
            extract_to.mkdir(parents=True, exist_ok=True)
            
            try:
                if file_path.suffix.lower() in ['.zip']:
                    with zipfile.ZipFile(file_path, 'r') as zip_ref:
                        zip_ref.extractall(extract_to)
                    print(f"Extracted ZIP file to {extract_to}")
                    return extract_to
                elif file_path.suffix.lower() in ['.tar', '.tar.gz', '.tgz']:
                    with tarfile.open(file_path, 'r:*') as tar_ref:
                        tar_ref.extractall(extract_to)
                    print(f"Extracted TAR file to {extract_to}")
                    return extract_to
                else:
                    print(f"File {file_path} is not a supported compressed format")
                    return file_path
            except Exception as e:
                print(f"Error extracting {file_path}: {e}")
                return file_path

        def set_seed(seed=42):
            random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)
            torch.cuda.manual_seed_all(seed); cudnn.deterministic = False; cudnn.benchmark = True

        def list_images_under_category(category_dir: Path):
            files = []
            if not category_dir.exists():
                print(f"Category directory does not exist: {category_dir}")
                return files
            
            print(f"Scanning category directory: {category_dir}")
            
            # First, check if images are directly in the category directory
            for f in category_dir.iterdir():
                if f.is_file() and f.suffix.lower() in IMG_EXTS:
                    files.append(f)
                    print(f"  Found image: {f.name}")
            
            # Then check subdirectories (component directories)
            for comp_dir in category_dir.iterdir():
                if comp_dir.is_dir():
                    print(f"  Checking subdirectory: {comp_dir.name}")
                    for f in comp_dir.iterdir():
                        if f.is_file() and f.suffix.lower() in IMG_EXTS:
                            files.append(f)
                            print(f"    Found image: {f.name}")
            
            print(f"Total images found in {category_dir.name}: {len(files)}")
            return files

        class UICategoryDataset(Dataset):
            def __init__(self, split_root: Path, category_to_idx: dict, transform=None):
                self.transform = transform
                self.samples = []
                self.category_to_idx = category_to_idx
                
                print(f"Initializing dataset from: {split_root}")
                print(f"Expected categories: {list(category_to_idx.keys())}")
                
                for cat in sorted(category_to_idx.keys()):
                    cat_dir = split_root / cat
                    print(f"\\nLooking for category: {cat}")
                    print(f"Category directory: {cat_dir}")
                    
                    if not cat_dir.exists(): 
                        print(f"  Category directory does not exist, skipping: {cat}")
                        continue
                        
                    for img_path in list_images_under_category(cat_dir):
                        self.samples.append((img_path, category_to_idx[cat]))
                
                print(f"Total samples found: {len(self.samples)}")
                if len(self.samples) == 0:
                    print("ERROR: No images found!")
                    print("Available directories in split_root:")
                    for item in split_root.iterdir():
                        if item.is_dir():
                            print(f"  - {item.name}/")
                    raise RuntimeError(f"No images found under {split_root}.")

            def __len__(self): return len(self.samples)

            def __getitem__(self, idx):
                path, y = self.samples[idx]
                img = Image.open(path).convert("RGB")
                if self.transform: img = self.transform(img)
                return img, y

        def accuracy(outputs, targets):
            preds = outputs.argmax(dim=1)
            return (preds == targets).float().mean().item()

        def evaluate(model, loader, device, criterion):
            model.eval()
            running_loss, running_acc, n = 0.0, 0.0, 0
            with torch.no_grad():
                for x, y in loader:
                    x, y = x.to(device), y.to(device)
                    with torch.cuda.amp.autocast():
                        logits = model(x)
                        loss = criterion(logits, y)
                    bs = y.size(0)
                    running_loss += loss.item() * bs
                    running_acc  += accuracy(logits, y) * bs
                    n += bs
            return running_loss / n, running_acc / n

        # Parse arguments
        parser = argparse.ArgumentParser()
        parser.add_argument('--train_dataset', type=str, required=True)
        parser.add_argument('--val_dataset', type=str, required=True)
        parser.add_argument('--test_dataset', type=str, required=True)
        parser.add_argument('--model_init', type=str, required=True)
        parser.add_argument('--model_meta', type=str, required=True)
        parser.add_argument('--trained_model', type=str, required=True)
        parser.add_argument('--label_maps', type=str, required=True)
        parser.add_argument('--train_log', type=str, required=True)
        parser.add_argument('--epochs', type=int, default=10)
        parser.add_argument('--batch_size', type=int, default=32)
        parser.add_argument('--lr', type=float, default=3e-4)
        parser.add_argument('--weight_decay', type=float, default=1e-4)
        parser.add_argument('--num_workers', type=int, default=2)
        parser.add_argument('--seed', type=int, default=42)
        args = parser.parse_args()

        print(f"Train dataset: {args.train_dataset}")
        print(f"Val dataset: {args.val_dataset}")
        print(f"Test dataset: {args.test_dataset}")
        print(f"Model init: {args.model_init}")
        print(f"Model meta: {args.model_meta}")
        print(f"Trained model output: {args.trained_model}")
        print(f"Label maps output: {args.label_maps}")
        print(f"Train log output: {args.train_log}")

        set_seed(args.seed)

        # Create output directories
        for output_path in [args.trained_model, args.label_maps, args.train_log]:
            output_dir = os.path.dirname(output_path)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir, exist_ok=True)

        # Load metadata
        try:
            # model_meta is passed as inputValue (JSON string content)
            meta = json.loads(args.model_meta)
            print("Loaded metadata from JSON string")
        except Exception as e:
            print(f"Error loading model metadata: {e}")
            exit(1)
            
        image_size = meta["image_size"]
        mean, std = meta["mean"], meta["std"]
        categories = meta["categories"]
        category_to_idx = {c:i for i,c in enumerate(categories)}
        idx_to_category = {i:c for c,i in category_to_idx.items()}

        train_tfms = transforms.Compose([
            transforms.Resize((image_size, image_size)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.15, hue=0.02),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std),
        ])
        eval_tfms = transforms.Compose([
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std),
        ])

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Using device: {device}")

        # Build datasets/loaders - handle Kubeflow's /data subdirectory
        train_input = Path(args.train_dataset)
        val_input = Path(args.val_dataset)
        
        # Handle the /data file/directory structure
        if (train_input / "data").exists():
            train_data_path = train_input / "data"
        else:
            train_data_path = train_input
            
        if (val_input / "data").exists():
            val_data_path = val_input / "data"
        else:
            val_data_path = val_input
            
        print(f"Train data path: {train_data_path}")
        print(f"Val data path: {val_data_path}")
        print(f"Train is file: {train_data_path.is_file()}")
        print(f"Val is file: {val_data_path.is_file()}")
        
        # Extract if compressed files
        if train_data_path.is_file():
            print("Train dataset appears to be a file - attempting extraction")
            train_path = extract_if_compressed(train_data_path, train_input / "extracted_train")
        else:
            train_path = train_data_path
            
        if val_data_path.is_file():
            print("Val dataset appears to be a file - attempting extraction")  
            val_path = extract_if_compressed(val_data_path, val_input / "extracted_val")
        else:
            val_path = val_data_path
            
        print(f"Final train path: {train_path}")
        print(f"Final val path: {val_path}")
        
        # Check if paths are now directories
        if not train_path.is_dir():
            print(f"ERROR: Train path is still not a directory: {train_path}")
            print("Contents of train input directory:")
            try:
                for item in train_input.iterdir():
                    item_type = "DIR" if item.is_dir() else "FILE"
                    size = f" ({item.stat().st_size} bytes)" if item.is_file() else ""
                    print(f"  {item_type}: {item.name}{size}")
            except Exception as e:
                print(f"Error listing directory: {e}")
            exit(1)
            
        if not val_path.is_dir():
            print(f"ERROR: Val path is still not a directory: {val_path}")
            print("Contents of val input directory:")
            try:
                for item in val_input.iterdir():
                    item_type = "DIR" if item.is_dir() else "FILE"
                    size = f" ({item.stat().st_size} bytes)" if item.is_file() else ""
                    print(f"  {item_type}: {item.name}{size}")
            except Exception as e:
                print(f"Error listing directory: {e}")
            exit(1)
        
        # Show directory structure
        print("=== DEBUG: Train dataset structure ===")
        def show_directory_structure(path, max_depth=3, current_depth=0):
            if current_depth >= max_depth:
                return
            try:
                for item in sorted(path.iterdir()):
                    indent = "  " * current_depth
                    if item.is_dir():
                        print(f"{indent}{item.name}/")
                        show_directory_structure(item, max_depth, current_depth + 1)
                    else:
                        print(f"{indent}{item.name}")
            except PermissionError:
                print(f"{indent}[Permission Denied]")
        
        show_directory_structure(train_path)
        print("=== END DEBUG ===")
        
        train_ds = UICategoryDataset(train_path, category_to_idx, transform=train_tfms)
        val_ds   = UICategoryDataset(val_path, category_to_idx, transform=eval_tfms)
        train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True,
                                  num_workers=args.num_workers, pin_memory=True)
        val_loader   = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False,
                                  num_workers=args.num_workers, pin_memory=True)

        # Load model - handle Kubeflow's /data subdirectory for model file
        model_init_path = Path(args.model_init)
        if (model_init_path / "data").exists() and (model_init_path / "data").is_file():
            model_init_path = model_init_path / "data"
        elif not model_init_path.is_file() and (model_init_path.parent / "data").exists():
            # Check if the file is actually in a data subdirectory
            potential_path = model_init_path.parent / "data" / model_init_path.name
            if potential_path.exists():
                model_init_path = potential_path
        
        print(f"Loading model from: {model_init_path}")
        
        try:
            state = torch.load(model_init_path, map_location="cpu")
            from torchvision.models import resnet50, ResNet50_Weights
            m = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)
            m.fc = nn.Sequential(nn.Dropout(p=0.2), nn.Linear(m.fc.in_features, len(categories)))
            m.load_state_dict(state, strict=True)
            m.to(device)
            print("Model loaded successfully")
        except Exception as e:
            print(f"Error loading model: {e}")
            print(f"Available files in {args.model_init}:")
            try:
                for p in Path(args.model_init).parent.iterdir():
                    print(f"  - {p}")
            except Exception:
                pass
            exit(1)

        # Loss/optim/sched
        criterion = nn.CrossEntropyLoss(label_smoothing=0.05)
        optimizer = torch.optim.AdamW(m.parameters(), lr=args.lr, weight_decay=args.weight_decay)

        total_steps = args.epochs * (len(train_loader) if len(train_loader) > 0 else 1)
        warmup_steps = max(100, int(0.05 * total_steps))
        def lr_lambda(step):
            if step < warmup_steps:
                return float(step) / float(max(1, warmup_steps))
            progress = (step - warmup_steps) / float(max(1, total_steps - warmup_steps))
            return 0.5 * (1.0 + math.cos(math.pi * progress))
        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)
        scaler = torch.cuda.amp.GradScaler()

        # Train
        print("Starting training...")
        best_val_acc = 0.0
        for epoch in range(1, args.epochs + 1):
            m.train(); epoch_loss = 0.0; epoch_acc = 0.0; seen = 0
            t0 = time.time()
            for x, y in train_loader:
                x, y = x.to(device), y.to(device)
                optimizer.zero_grad(set_to_none=True)
                with torch.cuda.amp.autocast():
                    logits = m(x)
                    loss = criterion(logits, y)
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
                scheduler.step()
                bs = y.size(0)
                epoch_loss += loss.item() * bs
                epoch_acc  += ((logits.argmax(1) == y).float().mean().item()) * bs
                seen += bs
            train_loss = epoch_loss / max(1, seen)
            train_acc  = epoch_acc  / max(1, seen)
            val_loss, val_acc = evaluate(m, val_loader, device, criterion)
            dt = time.time() - t0
            print(f"Epoch {epoch:02d}/{args.epochs} | {dt:.1f}s | train loss {train_loss:.4f} acc {train_acc:.3f} | val loss {val_loss:.4f} acc {val_acc:.3f}")

            if val_acc > best_val_acc:
                best_val_acc = val_acc
                torch.save({
                    "model_state": m.state_dict(),
                    "category_to_idx": category_to_idx,
                    "idx_to_category": idx_to_category,
                    "image_size": image_size,
                }, args.trained_model)
                print(f"âœ“ Saved new best to {args.trained_model} (val_acc={val_acc:.3f})")

        # Save sidecar outputs
        try:
            label_maps_data = {
                "category_to_idx": category_to_idx, 
                "idx_to_category": idx_to_category
            }
            with open(args.label_maps, 'w') as f:
                json.dump(label_maps_data, f, indent=2)
            
            train_log_data = {
                "best_val_acc": best_val_acc
            }
            with open(args.train_log, 'w') as f:
                json.dump(train_log_data, f, indent=2)
            
            print(f"Saved label maps to {args.label_maps}")
            print(f"Saved training log to {args.train_log}")
            print(f"Best validation accuracy: {best_val_acc:.3f}")
        except Exception as e:
            print(f"Error saving outputs: {e}")
            exit(1)
    args:
      - --train_dataset
      - {inputPath: train_dataset}
      - --val_dataset
      - {inputPath: val_dataset}
      - --test_dataset
      - {inputPath: test_dataset}
      - --model_init
      - {inputPath: model_init}
      - --model_meta
      - {inputValue: model_meta}
      - --trained_model
      - {outputPath: trained_model}
      - --label_maps
      - {outputPath: label_maps}
      - --train_log
      - {outputPath: train_log}
