name: phase1_train
description: Train the Phase 1 ResNet50 classifier using the provided dataset and model initialization.

inputs:
  - { name: train_data, type: Dataset, description: "Training dataset" }
  - { name: val_data, type: Dataset, description: "Validation dataset" }
  - { name: test_data, type: Dataset, description: "Test dataset" }
  - { name: model_init, type: Model, description: "Model initialization weights (phase1_model_init.pt)" }
  - { name: model_meta, type: String, description: "Model metadata JSON (phase1_model_meta.json)" }

outputs:
  - { name: trained_model, type: Model, description: "Best trained model checkpoint (phase1_resnet50_best.pt)" }
  - { name: label_maps, type: String, description: "Label mappings JSON (phase1_label_maps.json)" }
  - { name: train_log, type: String, description: "Training log JSON (phase1_train_log.json)" }

implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        # Install required dependencies
        pip install torch torchvision pillow numpy scikit-learn --index-url https://download.pytorch.org/whl/cpu
        
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        #!/usr/bin/env python3
        import argparse
        import json
        import math
        import random
        import time
        import os
        import pickle
        from pathlib import Path
        import numpy as np
        import torch
        import torch.nn as nn
        import torch.backends.cudnn as cudnn
        from torch.utils.data import Dataset, DataLoader
        from torchvision import transforms
        from torchvision.models import resnet50, ResNet50_Weights
        from PIL import Image

        IMG_EXTS = {".jpg", ".jpeg", ".png", ".webp"}

        def set_seed(seed=42):
            random.seed(seed)
            np.random.seed(seed)
            torch.manual_seed(seed)
            torch.cuda.manual_seed_all(seed)
            cudnn.deterministic = False
            cudnn.benchmark = True

        def list_images_under_category(category_dir: Path):
            files = []
            for comp_dir in category_dir.iterdir():
                if comp_dir.is_dir():
                    for f in comp_dir.iterdir():
                        if f.is_file() and f.suffix.lower() in IMG_EXTS:
                            files.append(f)
            return files

        class UICategoryDataset(Dataset):
            def __init__(self, split_root: Path, category_to_idx: dict, transform=None):
                self.transform = transform
                self.samples = []
                self.category_to_idx = category_to_idx
                
                # Handle the case where split_root is the actual data directory
                if split_root.is_dir():
                    for cat in sorted(category_to_idx.keys()):
                        cat_dir = split_root / cat
                        if not cat_dir.exists(): 
                            continue
                        for img_path in list_images_under_category(cat_dir):
                            self.samples.append((img_path, category_to_idx[cat]))
                
                if len(self.samples) == 0:
                    raise RuntimeError(f"No images found under {split_root}.")

            def __len__(self):
                return len(self.samples)

            def __getitem__(self, idx):
                path, y = self.samples[idx]
                img = Image.open(path).convert("RGB")
                if self.transform:
                    img = self.transform(img)
                return img, y

        def accuracy(outputs, targets):
            preds = outputs.argmax(dim=1)
            return (preds == targets).float().mean().item()

        def evaluate(model, loader, device, criterion):
            model.eval()
            running_loss, running_acc, n = 0.0, 0.0, 0
            with torch.no_grad():
                for x, y in loader:
                    x, y = x.to(device), y.to(device)
                    with torch.cuda.amp.autocast():
                        logits = model(x)
                        loss = criterion(logits, y)
                    bs = y.size(0)
                    running_loss += loss.item() * bs
                    running_acc  += accuracy(logits, y) * bs
                    n += bs
            return running_loss / n, running_acc / n

        def main():
            parser = argparse.ArgumentParser()
            parser.add_argument('--train_data', type=str, required=True)
            parser.add_argument('--val_data', type=str, required=True)
            parser.add_argument('--test_data', type=str, required=True)
            parser.add_argument('--model_init', type=str, required=True)
            parser.add_argument('--model_meta', type=str, required=True)
            parser.add_argument('--trained_model', type=str, required=True)
            parser.add_argument('--label_maps', type=str, required=True)
            parser.add_argument('--train_log', type=str, required=True)
            parser.add_argument('--epochs', type=int, default=10)
            parser.add_argument('--batch_size', type=int, default=32)
            parser.add_argument('--lr', type=float, default=3e-4)
            parser.add_argument('--weight_decay', type=float, default=1e-4)
            parser.add_argument('--num_workers', type=int, default=2)
            parser.add_argument('--seed', type=int, default=42)
            args = parser.parse_args()

            set_seed(args.seed)

            # Ensure output directories exist
            os.makedirs(os.path.dirname(args.trained_model), exist_ok=True)
            os.makedirs(os.path.dirname(args.label_maps), exist_ok=True)
            os.makedirs(os.path.dirname(args.train_log), exist_ok=True)

            # Load dataset paths from pickle files
            def load_dataset_path(dataset_pickle_path):
                with open(dataset_pickle_path, 'rb') as f:
                    dataset_info = pickle.load(f)
                if isinstance(dataset_info, dict) and 'data_path' in dataset_info:
                    return Path(dataset_info['data_path'])
                else:
                    return Path(dataset_pickle_path)

            train_path = load_dataset_path(args.train_data)
            val_path = load_dataset_path(args.val_data)
            test_path = load_dataset_path(args.test_data)

            # Load model metadata - handle both direct JSON and pickle file
            try:
                if args.model_meta.endswith('.json'):
                    with open(args.model_meta, 'r') as f:
                        meta = json.load(f)
                else:
                    with open(args.model_meta, 'rb') as f:
                        meta = pickle.load(f)
            except Exception as e:
                print(f"Error loading model meta: {e}")
                exit(1)

            image_size = meta["image_size"]
            mean, std = meta["mean"], meta["std"]
            categories = meta["categories"]
            category_to_idx = {c:i for i,c in enumerate(categories)}
            idx_to_category = {i:c for c,i in category_to_idx.items()}

            print(f"Dataset root: {dataset_root_path}")
            print(f"Categories: {categories}")
            print(f"Number of classes: {len(categories)}")

            train_tfms = transforms.Compose([
                transforms.Resize((image_size, image_size)),
                transforms.RandomHorizontalFlip(p=0.5),
                transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),
                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.15, hue=0.02),
                transforms.ToTensor(),
                transforms.Normalize(mean=mean, std=std),
            ])
            eval_tfms = transforms.Compose([
                transforms.Resize((image_size, image_size)),
                transforms.ToTensor(),
                transforms.Normalize(mean=mean, std=std),
            ])

            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            print(f"Using device: {device}")

            # Build datasets/loaders
            train_ds = UICategoryDataset(dataset_root_path / "train", category_to_idx, transform=train_tfms)
            val_ds = UICategoryDataset(dataset_root_path / "val", category_to_idx, transform=eval_tfms)
            train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True,
                                      num_workers=args.num_workers, pin_memory=True)
            val_loader = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False,
                                    num_workers=args.num_workers, pin_memory=True)

            print(f"Train samples: {len(train_ds)}, Val samples: {len(val_ds)}")

            # Load model
            state = torch.load(args.model_init, map_location="cpu")
            # Rebuild the same architecture used in model_def
            model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)
            model.fc = nn.Sequential(
                nn.Dropout(p=0.2), 
                nn.Linear(model.fc.in_features, len(categories))
            )
            model.load_state_dict(state, strict=True)
            model.to(device)

            # Loss/optim/sched
            criterion = nn.CrossEntropyLoss(label_smoothing=0.05)
            optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)

            total_steps = args.epochs * (len(train_loader) if len(train_loader) > 0 else 1)
            warmup_steps = max(100, int(0.05 * total_steps))
            
            def lr_lambda(step):
                if step < warmup_steps:
                    return float(step) / float(max(1, warmup_steps))
                progress = (step - warmup_steps) / float(max(1, total_steps - warmup_steps))
                return 0.5 * (1.0 + math.cos(math.pi * progress))
            
            scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)
            scaler = torch.cuda.amp.GradScaler()

            # Training loop
            best_val_acc = 0.0
            print("Starting training...")
            
            for epoch in range(1, args.epochs + 1):
                model.train()
                epoch_loss = 0.0
                epoch_acc = 0.0
                seen = 0
                t0 = time.time()
                
                for x, y in train_loader:
                    x, y = x.to(device), y.to(device)
                    optimizer.zero_grad(set_to_none=True)
                    with torch.cuda.amp.autocast():
                        logits = model(x)
                        loss = criterion(logits, y)
                    scaler.scale(loss).backward()
                    scaler.step(optimizer)
                    scaler.update()
                    scheduler.step()
                    bs = y.size(0)
                    epoch_loss += loss.item() * bs
                    epoch_acc  += accuracy(logits, y) * bs
                    seen += bs
                    
                train_loss = epoch_loss / max(1, seen)
                train_acc  = epoch_acc  / max(1, seen)
                val_loss, val_acc = evaluate(model, val_loader, device, criterion)
                dt = time.time() - t0
                
                print(f"Epoch {epoch:02d}/{args.epochs} | {dt:.1f}s | train loss {train_loss:.4f} acc {train_acc:.3f} | val loss {val_loss:.4f} acc {val_acc:.3f}")

                if val_acc > best_val_acc:
                    best_val_acc = val_acc
                    torch.save({
                        "model_state": model.state_dict(),
                        "category_to_idx": category_to_idx,
                        "idx_to_category": idx_to_category,
                        "image_size": image_size,
                    }, args.trained_model)
                    print(f"âœ“ Saved new best model (val_acc={val_acc:.3f})")

            # Save label maps
            with open(args.label_maps, 'w') as f:
                json.dump({
                    "category_to_idx": category_to_idx,
                    "idx_to_category": idx_to_category
                }, f, indent=2)

            # Save training log
            with open(args.train_log, 'w') as f:
                json.dump({
                    "best_val_acc": best_val_acc
                }, f, indent=2)

            print(f"Training completed. Best val acc: {best_val_acc:.3f}")
            print(f"Trained model saved to: {args.trained_model}")
            print(f"Label maps saved to: {args.label_maps}")
            print(f"Training log saved to: {args.train_log}")

        if __name__ == "__main__":
            main()

    args:
      - --train_data
      - {inputPath: train_data}
      - --val_data
      - {inputPath: val_data}
      - --test_data
      - {inputPath: test_data}
      - --model_init
      - {inputPath: model_init}
      - --model_meta
      - {inputPath: model_meta}
      - --trained_model
      - {outputPath: trained_model}
      - --label_maps
      - {outputPath: label_maps}
      - --train_log
      - {outputPath: train_log}
